import time
import json
import traceback
import logging

from flask import Flask, request, jsonify, Response
import g4f  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ g4f –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ

app = Flask(__name__)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
)

def get_chat_response(message, specific_provider=None, use_stream=False, timeout=20):
    """
    –†–µ–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –æ—Ç G4F –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤.
    """
    import g4f
    import time
    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ —Ä–∞–±–æ—Ç–∞—é—â–∏–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã
    from g4f.Provider import FreeGpt,HuggingChat, DeepInfra, You, Qwen_Qwen_2_5_Max, Qwen_Qwen_2_5, Qwen_Qwen_2_5M, Qwen_Qwen_2_72B

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ (—Ç–æ–ª—å–∫–æ –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ —Ä–∞–±–æ—Ç–∞—é—â–∏–µ)
    provider_map = {
        "Qwen_Qwen_2_72B": Qwen_Qwen_2_72B,
        "Qwen_Qwen_2_5_Max": Qwen_Qwen_2_5_Max,
        "Qwen_Qwen_2_5": Qwen_Qwen_2_5,
        "Qwen_Qwen_2_5M": Qwen_Qwen_2_5M,
        "FreeGpt": FreeGpt,
        "HuggingChat": HuggingChat,
        "DeepInfra": DeepInfra,
        "You": You
    }

    if specific_provider is None:
        specific_provider = "Qwen_Qwen_2_72B"

    # –í—ã–±–∏—Ä–∞–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä
    selected_provider = provider_map.get(specific_provider, Qwen_Qwen_2_72B)

    # –í—ã–±–∏—Ä–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
    if specific_provider == "Qwen_Qwen_2_5_Max":
        model = "qwen-max"
    elif specific_provider == "Qwen_Qwen_2_5":
        model = "qwen-2.5"
    elif specific_provider == "Qwen_Qwen_2_5M":
        model = "qwen-2.5"
    elif specific_provider == "Qwen_Qwen_2_72B":
        model = "qwen-2.5-72b"
    elif specific_provider == "You":
        model = "gpt-4o-mini"
    elif specific_provider == "HuggingChat":
        model = "llama-3.1-70b"
    elif specific_provider == "Blackbox":
        model = "blackbox"
    else:
        model = "gpt-4o-mini"

    try:
        start_time = time.time()

        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç –¥–ª—è –±–æ–ª—å—à–∏—Ö –º–æ–¥–µ–ª–µ–π
        if specific_provider == "Qwen_Qwen_2_72B":
            timeout = max(timeout, 45)  # –ú–∏–Ω–∏–º—É–º 45 —Å–µ–∫—É–Ω–¥ –¥–ª—è 72B –º–æ–¥–µ–ª–∏
        elif specific_provider in ["Qwen_Qwen_2_5_Max", "Qwen_Qwen_2_5"]:
            timeout = max(timeout, 30)  # 30 —Å–µ–∫—É–Ω–¥ –¥–ª—è –¥—Ä—É–≥–∏—Ö –±–æ–ª—å—à–∏—Ö –º–æ–¥–µ–ª–µ–π

        # –°–æ–∑–¥–∞–µ–º –∑–∞–ø—Ä–æ—Å –∫ G4F —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –º–æ–¥–µ–ª—å—é
        response = g4f.ChatCompletion.create(
            model=model,
            messages=[{"role": "user", "content": message}],
            provider=selected_provider,
            stream=use_stream,
            timeout=timeout
        )

        elapsed = time.time() - start_time

        if use_stream:
            return {
                "streaming": True,
                "provider": specific_provider,
                "model": model,
                "response_stream": response,
                "elapsed": elapsed
            }
        else:
            return {
                "success": True,
                "response": str(response),
                "provider": specific_provider,
                "model": model,
                "elapsed": elapsed
            }

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ G4F –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ {specific_provider}: {str(e)}")

        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ –¥—Ä—É–≥–∏–µ —Ä–∞–±–æ—á–∏–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã
        backup_providers = ["Qwen_Qwen_2_72B", "Qwen_Qwen_2_5_Max", "Qwen_Qwen_2_5", "Qwen_Qwen_2_5M"]

        for backup_provider in backup_providers:
            if backup_provider != specific_provider:
                try:
                    print(f"üîÑ –ü—Ä–æ–±—É–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä: {backup_provider}")
                    backup_selected = provider_map.get(backup_provider)

                    if backup_provider == "Qwen_Qwen_2_5_Max":
                        backup_model = "qwen-max"
                    elif backup_provider == "Qwen_Qwen_2_72B":
                        backup_model = "qwen-2.5-72b"
                    else:
                        backup_model = "qwen-2.5"

                    backup_response = g4f.ChatCompletion.create(
                        model=backup_model,
                        messages=[{"role": "user", "content": message}],
                        provider=backup_selected,
                        stream=use_stream,
                        timeout=timeout
                    )

                    print(f"‚úÖ –†–µ–∑–µ—Ä–≤–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä {backup_provider} —Å—Ä–∞–±–æ—Ç–∞–ª!")

                    if use_stream:
                        return {
                            "streaming": True,
                            "provider": backup_provider,
                            "model": backup_model,
                            "response_stream": backup_response,
                            "elapsed": time.time() - start_time
                        }
                    else:
                        return {
                            "success": True,
                            "response": str(backup_response),
                            "provider": backup_provider,
                            "model": backup_model,
                            "elapsed": time.time() - start_time
                        }

                except Exception as backup_error:
                    print(f"‚ùå –†–µ–∑–µ—Ä–≤–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä {backup_provider}: {str(backup_error)}")
                    continue

        # –ï—Å–ª–∏ –≤—Å–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏
        return {
            "success": True,
            "response": f"–ò–∑–≤–∏–Ω–∏—Ç–µ, –≤–æ–∑–Ω–∏–∫–ª–∞ –ø—Ä–æ–±–ª–µ–º–∞ —Å –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–º {specific_provider}. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.",
            "provider": f"{specific_provider}_fallback",
            "model": "fallback",
            "elapsed": 0.1
        }

def get_demo_response(message):
    """–ü–æ–ª—É—á–∏—Ç—å –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –¥–ª—è —Å–æ–æ–±—â–µ–Ω–∏—è"""
    message_lower = message.lower()

    if any(word in message_lower for word in ['–ø—Ä–∏–≤–µ—Ç', 'hello', 'hi', '–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π']):
        return "–ü—Ä–∏–≤–µ—Ç! –†–∞–¥ –≤–∞—Å –≤–∏–¥–µ—Ç—å! üòä –Ø BOOOMERANGS AI - –≤–∞—à —Ç–≤–æ—Ä—á–µ—Å–∫–∏–π –ø–æ–º–æ—â–Ω–∏–∫. –ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?"
    elif any(word in message_lower for word in ['—á—Ç–æ —Ç–∞–∫–æ–µ', '—Ä–∞—Å—Å–∫–∞–∂–∏ –æ', '—á—Ç–æ —Ç—ã', '–æ —Å–µ–±–µ']):
        return "–ü—Ä–∏–≤–µ—Ç! –ú–µ–Ω—è –∑–æ–≤—É—Ç BOOOMERANGS AI, –∏ —è –≤–∞—à —Ç–≤–æ—Ä—á–µ—Å–∫–∏–π –ø–æ–º–æ—â–Ω–∏–∫!\n\nüöÄ **–ú–æ–∏ —Å—É–ø–µ—Ä—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏:**\n‚Ä¢ –°–æ–∑–¥–∞—é —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ –æ–ø–∏—Å–∞–Ω–∏—é\n‚Ä¢ –ü—Ä–µ–≤—Ä–∞—â–∞—é –∫–∞—Ä—Ç–∏–Ω–∫–∏ –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –≥—Ä–∞—Ñ–∏–∫—É\n‚Ä¢ –ì–æ—Ç–æ–≤–ª—é –¥–∏–∑–∞–π–Ω—ã –¥–ª—è –≤—ã—à–∏–≤–∞–ª—å–Ω—ã—Ö –º–∞—à–∏–Ω\n‚Ä¢ –ö–æ–Ω—Å—É–ª—å—Ç–∏—Ä—É—é –ø–æ —Ç–≤–æ—Ä—á–µ—Å–∫–∏–º –ø—Ä–æ–µ–∫—Ç–∞–º\n‚Ä¢ –ü—Ä–æ—Å—Ç–æ —Ö–æ—Ä–æ—à–æ –æ–±—â–∞—é—Å—å –Ω–∞ –ª—é–±—ã–µ —Ç–µ–º—ã!\n\n–ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?"
    elif any(word in message_lower for word in ['—Å–æ–∑–¥–∞–π', '–Ω–∞—Ä–∏—Å—É–π', '—Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π']):
        return "–û—Ç–ª–∏—á–Ω–æ! –û–ø–∏—à–∏—Ç–µ –ø–æ–¥—Ä–æ–±–Ω–µ–µ —á—Ç–æ –≤—ã —Ö–æ—Ç–∏—Ç–µ —Å–æ–∑–¥–∞—Ç—å, –∏ —è —Å–≥–µ–Ω–µ—Ä–∏—Ä—É—é –¥–ª—è –≤–∞—Å —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ! üé®"
    else:
        return "–ü–æ–Ω—è–ª! –ß–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ –º–æ–≥—É –ø–æ–º–æ—á—å? –ì–æ—Ç–æ–≤ —Å–æ–∑–¥–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫–∏ –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ –ø–æ–±–æ–ª—Ç–∞—Ç—å! üòä"

def stream_response_generator(message, provider, timeout):
    """
    –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –¥–ª—è –ø–æ—Ç–æ–∫–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –≤ /python/chat/stream
    """
    start_time = time.time()
    try:
        result = get_chat_response(message, specific_provider=provider, use_stream=True, timeout=timeout)
        yield f"data: {json.dumps({'status': 'start', 'provider': result.get('provider')})}\n\n"

        if result.get('streaming') and 'response_stream' in result:
            full_response = ''
            for chunk in result['response_stream']:
                if "<html" in chunk.lower():
                    error_msg = '–ü—Ä–æ–≤–∞–π–¥–µ—Ä –≤–µ—Ä–Ω—É–ª HTML –≤–º–µ—Å—Ç–æ —Ç–µ–∫—Å—Ç–∞ ‚Äî –≤–æ–∑–º–æ–∂–Ω–æ, –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω'
                    logging.error(error_msg)
                    yield f"data: {json.dumps({'error': error_msg})}\n\n"
                    break
                yield f"data: {json.dumps({'chunk': chunk, 'provider': result.get('provider')})}\n\n"
                full_response += chunk

            elapsed = time.time() - start_time
            yield f"data: {json.dumps({'status': 'done', 'full_text': full_response, 'provider': result.get('provider'), 'model': result.get('model'), 'elapsed': elapsed})}\n\n"
        else:
            # –°—Ç—Ä–∏–º–∏–Ω–≥ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –∏–ª–∏ –æ—à–∏–±–∫–∞
            if "error" in result:
                demo_response = get_demo_response(message)
                error_data = {
                    'error': result.get('error'),
                    'text': demo_response,
                    'provider': 'BOOOMERANGS-Demo'
                }
                yield f"data: {json.dumps(error_data)}\n\n"
                yield f"data: {json.dumps({'status': 'done', 'full_text': demo_response, 'provider': 'BOOOMERANGS-Demo', 'model': 'fallback-mode', 'elapsed': time.time() - start_time})}\n\n"
            else:
                text_data = {
                    'text': result.get('response'),
                    'provider': result.get('provider')
                }
                yield f"data: {json.dumps(text_data)}\n\n"
                yield f"data: {json.dumps({'status': 'done', 'full_text': result.get('response'), 'provider': result.get('provider'), 'model': result.get('model'), 'elapsed': result.get('elapsed', time.time() - start_time)})}\n\n"

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ —Å—Ç—Ä–∏–º–∏–Ω–≥–∞: {str(e)}", exc_info=True)
        error_data = {'error': str(e)}
        yield f"data: {json.dumps(error_data)}\n\n"
        demo_response = get_demo_response(message)
        text_data = {'text': demo_response, 'provider': 'BOOOMERANGS-Error'}
        yield f"data: {json.dumps(text_data)}\n\n"
        yield f"data: {json.dumps({'status': 'done', 'full_text': demo_response, 'provider': 'BOOOMERANGS-Error', 'model': 'error-mode', 'elapsed': time.time() - start_time})}\n\n"

@app.route('/python/chat', methods=['POST'])
def chat():
    """
    –û—Å–Ω–æ–≤–Ω–æ–π —ç–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è —á–∞—Ç–∞ —Å AI –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞–º–∏.
    –û–∂–∏–¥–∞–µ—Ç JSON —Å –ø–æ–ª—è–º–∏: message, provider (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ).
    """
    try:
        data = request.json or {}
        message = data.get('message', '')
        provider_name = data.get('provider', 'Qwen_Qwen_2_72B')

        if not message:
            return jsonify({"error": "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ"}), 400

        result = get_chat_response(message, provider_name)
        return jsonify(result)

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —á–∞—Ç–µ: {str(e)}", exc_info=True)
        return jsonify({
            "error": str(e),
            "response": f"–û—à–∏–±–∫–∞ AI –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞: {str(e)}",
            "provider": "error"
        }), 500

@app.route('/python/chat/direct', methods=['POST'])
def chat_direct():
    """
    –≠–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –ø—Ä—è–º–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É –ø—Ä–æ–≤–∞–π–¥–µ—Ä—É.
    –û–∂–∏–¥–∞–µ—Ç JSON —Å –ø–æ–ª—è–º–∏: message, provider, model, timeout.
    """
    try:
        data = request.json or {}
        message = data.get('message', '')
        provider_name = data.get('provider')
        model = data.get('model')
        timeout = data.get('timeout', 20)

        if not message:
            return jsonify({"error": "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ"}), 400

        if provider_name and hasattr(g4f.Provider, provider_name):
            provider = getattr(g4f.Provider, provider_name)
            start_time = time.time()
            response = provider(
                prompt=message,
                model=model,
                timeout=timeout
            )
            elapsed = time.time() - start_time

            if isinstance(response, str) and "<html" in response.lower():
                raise Exception(f"–ü—Ä–æ–≤–∞–π–¥–µ—Ä {provider_name} –≤–µ—Ä–Ω—É–ª HTML –≤–º–µ—Å—Ç–æ —Ç–µ–∫—Å—Ç–∞")

            logging.info(f"‚úÖ –ü—Ä–æ–≤–∞–π–¥–µ—Ä {provider_name} —É—Å–ø–µ—à–Ω–æ –æ—Ç–≤–µ—Ç–∏–ª –∑–∞ {elapsed:.2f} —Å–µ–∫")

            return jsonify({
                "success": True,
                "response": response,
                "provider": provider_name,
                "model": model,
                "elapsed": elapsed
            })
        else:
            error_msg = f"–ü—Ä–æ–≤–∞–π–¥–µ—Ä {provider_name} –Ω–µ –Ω–∞–π–¥–µ–Ω"
            logging.error(error_msg)
            return jsonify({
                "error": error_msg,
                "response": f"–ü—Ä–æ–≤–∞–π–¥–µ—Ä {provider_name} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Å–∏—Å—Ç–µ–º–µ",
                "provider": "unknown"
            }), 404
    except Exception as e:
        logging.error(f"–û–±—â–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä—è–º–æ–º –≤—ã–∑–æ–≤–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞: {str(e)}", exc_info=True)
        return jsonify({
            "error": str(e),
            "response": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞: {str(e)}",
            "provider": "error"
        }), 500

@app.route('/python/test', methods=['POST'])
def test():
    """
    –¢–µ—Å—Ç–æ–≤—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–∞–±–æ—Ç—ã —Å —Å–∞–º—ã–º –Ω–∞–¥—ë–∂–Ω—ã–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–º.
    """
    try:
        data = request.json or {}
        message = data.get('message', 'test')

        result = get_chat_response(message, specific_provider="DeepInfra")
        return jsonify(result)
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏: {str(e)}", exc_info=True)
        return jsonify({
            "error": str(e),
            "response": "–¢–µ—Å—Ç –ø—Ä–æ–≤–∞–ª–∏–ª—Å—è: " + str(e),
            "provider": "BOOOMERANGS-Test",
            "model": "test-mode"
        }), 500

@app.route('/python/chat/stream', methods=['POST'])
def chat_stream():
    """
    –≠–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –ø–æ—Ç–æ–∫–æ–≤–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤.
    –û–∂–∏–¥–∞–µ—Ç JSON —Å –ø–æ–ª—è–º–∏: message (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ), provider (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ), timeout (–º—Å).
    """
    if request.method != 'POST':
        return Response('–ú–µ—Ç–æ–¥ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è', status=405)

    data = request.json or {}
    message = data.get('message', '')
    provider = data.get('provider')
    try:
        timeout = float(data.get('timeout', 20000)) / 1000
        if timeout <= 0 or timeout > 60:
            timeout = 20  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Ç–∞–π–º-–∞—É—Ç–∞ –º–∞–∫—Å–∏–º—É–º 60 —Å–µ–∫—É–Ω–¥
    except (ValueError, TypeError):
        timeout = 20

    if not message:
        return jsonify({"error": "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ"}), 400

    return Response(
        stream_response_generator(message, provider, timeout),
        mimetype='text/event-stream',
        headers={
            'Cache-Control': 'no-cache',
            'Connection': 'keep-alive',
            'X-Accel-Buffering': 'no'
        }
    )

@app.route('/')
def index():
    """
    –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç–æ–≤—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç.
    """
    return "BOOOMERANGS Python G4F API —Ä–∞–±–æ—Ç–∞–µ—Ç!"

@app.route('/health')
def health():
    """
    Health check endpoint.
    """
    return jsonify({
        "status": "ok",
        "service": "G4F Python Provider",
        "port": "5004",
        "providers": 104,
        "timestamp": time.time()
    })

def stream_response():
    """–û–¢–ö–õ–Æ–ß–ï–ù–û: –î–µ–º–æ-–æ—Ç–≤–µ—Ç—ã –∑–∞–º–µ–Ω–µ–Ω—ã –¥—É–º–∞—é—â–µ–π —Å–∏—Å—Ç–µ–º–æ–π"""
    # –í–º–µ—Å—Ç–æ –¥–µ–º–æ-–æ—Ç–≤–µ—Ç–æ–≤ –∞–∫—Ç–∏–≤–∏—Ä—É–µ–º –¥—É–º–∞—é—â—É—é —Å–∏—Å—Ç–µ–º—É Node.js
    yield f"data: {json.dumps({'role': 'assistant', 'content': 'THINKING_SYSTEM_ACTIVATION'})}\n\n"

if __name__ == '__main__':
    available_providers = [name for name in dir(g4f.Provider) if not name.startswith('_') and name[0].isupper()]
    logging.info(f"ü§ñ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(available_providers)} –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤: {', '.join(available_providers)}")

    # –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
    app.run(host='0.0.0.0', port=5004, debug=False)